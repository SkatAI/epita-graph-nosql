# no-sql and graph databases

This course covers a graph databse and a no-sql database, neo4j and mongodb

Before we dive into these 2 specific and amazing tools / platforms, the question is

what is a database

img : big bang + sheldon what is a database?

I've heard people talk about a csv file as a database. and it makes me cringe.
How can something so simple as a csv file can be put on the same level as engineering wonders such as PostgresSQL, weaviate, MongoDB, Neo4j, Redis etc ...

(I hear some people call csv files,  `excel` for some reason).

So I asked my dear friend GPT-4o, and this is what it told me

> In layman's terms:
    "A database is like a super-smart notebook or filing system that helps you keep track of lots of information and find exactly what you need in no time."

which definitely includes csv files, excel files, json files, XML files and so many other simple types of files based on one unique document.

if we ask a more classic and venerable source of knowledge, [Britanica](https://www.britannica.com/technology/database) we get:

> database, any collection of data, or information, that is specially organized for rapid search and retrieval by a computer. Databases are structured to facilitate the storage, retrieval, modification, and deletion of data in conjunction with various data-processing operations.

very interesting. we're no longer talking about finding information quickly (the retrieval part) but also

- storage
- modification
- deletion

That's where a simple spreadsheet no longer fits the purpose.

## What we expect from a DBMS

DBMS: database management system

TODO: edit below, split between what Excel can do and what DBMS are needed for.

1. **Data Storage and Retrieval**
   - **What it does:** Stores data in an organized manner and retrieves it when needed.
   - **Example:** You search for a specific customer record, and the DBMS finds it quickly.

2. **Data Manipulation**
    - **What it does:** Allows you to add, modify, or delete data.
    - **Example:** You can update a product price or remove an outdated entry.

3. **Data Querying**
    - **What it does:** Lets you ask complex questions (queries) about the data.
    - **Example:** "What are the top 10 most-sold products this year?"

4. **Data Organization**
    - **What it does:** Structures data in formats like tables, documents, or graphs to make it easy to manage.
    - **Example:** In a relational database, data is stored in rows and columns (like a spreadsheet).

10. **Data Sharing**
    - **What it does:** Allows multiple users or applications to use the database simultaneously.
    - **Example:** An online shopping site where users, admins, and inventory systems access the same database.

5. **Data Security**
    - **What it does:** Protects data from unauthorized access or corruption.
    - **Features:**
    - User authentication (e.g., username and password)
    - Permissions to control who can view or edit specific data.

-- this is where a solid DBMS is needed

6. **Concurrency Control**
    - **What it does:** Manages multiple users accessing the database at the same time without conflicts.
    - **Example:** Two employees updating the same customer file simultaneously won't mess up the data.

7. **Backup and Recovery**
    - **What it does:** Ensures that data is not lost and can be restored in case of failures.
    - **Example:** If the server crashes, you can recover data from the last backup.

8. **Data Integrity**
    - **What it does:** Ensures the data remains accurate, consistent, and reliable.
    - **Example:** A customer cannot have a negative account balance.

9. **Performance Optimization**
    - **What it does:** Provides tools to optimize speed and efficiency for data retrieval and updates.
    - **Example:** Indexing helps queries run faster.

11. **Support for Transactions**
    - **What it does:** Ensures a group of operations (transactions) is completed entirely or not at all.
    - **Example:** When transferring money between accounts, the transfer only goes through if both accounts are updated successfully.

## A brief history of databases 1970-2024

### 1970s - The Relational Era Begins

- **1970**: **Edgar Codd** publishes "A Relational Model of Data for Large Shared Data Banks"
- **1974**: **IBM** develops System R, the first SQL DBMS prototype
- **1979**: **Oracle** releases the first commercial SQL implementation

### 1980s - Relational Dominance

- **1986**: IBM DB2 released for mainframe
- **1989**: Postgres (now PostgreSQL) development begins at UC Berkeley -> best in class multi purpose database. can handle no-sql & vector, many extensions (http, postgis, ...). amazing performance. and OPEN SOURCE (free, effficient and secure)

### 1990s - Object-Oriented Wave

- **1991**: Object-Oriented Databases gain attention

Although most OODBs from the 90's have no lnger used, NoSQL and SQL databases incorporate object-oriented principles:

- MongoDB: Stores complex objects as documents
- Neo4j: Nodes can be viewed as objects with properties
- PostgreSQL: Offers object-relational features

- **1995**: MySQL released as open source
- **1998**: XML databases emerge for semi-structured data

## 2000s - NoSQL Revolution Begins

- **2004**: Google publishes BigTable paper, influencing future NoSQL systems
- **2007**: Amazon releases Dynamo paper, introducing eventual consistency
- **2009**: MongoDB released by 10gen (now MongoDB Inc.)
- **2009**: Neo4j becomes the first graph database to be released

So we start in 2009, 15 years ago.

## 2010s - NoSQL Matures & Specialization

- **2011**: Cassandra reaches Apache top-level project status
- **2012**: **Graph databases** gain traction with Facebook's graph search
- **2013**: Docker containers revolutionize database deployment
- **2015**: **Time-series databases** like InfluxDB gain popularity
- **2016**: Redis becomes the most popular **key-value** store
- **2018**: Multi-model databases emerge, combining different paradigms

## 2020s - AI & Vector Era

- **2020**: **Vector databases** like Milvus and Weaviate gain prominence for AI applications
- **2021**: Graph databases see increased adoption in machine learning
- **2022**: Vector search capabilities added to traditional databases
- **2023**: Emergence of RAG (Retrieval Augmented Generation) drives vector DB adoption
- **2024**: AI-native databases begin to appear

![evolution of databases](/img/epita-atabase-evolution-2024-11-21-062329.png)

![evolution of databases](/img/evolution-of-databases.png)

see also the chatGPT version

---

### **Timeline of Database Evolution**

The evolution of databases reflects the changing needs of organizations, from simple data storage to managing complex, real-time, and large-scale data systems. Here's a descriptive timeline:

---

#### **1960s: Birth of Databases**

- **Hierarchical Databases (e.g., IBM IMS, 1966):**
  - First generation of databases organized in a tree-like structure.
  - Used in early applications like banking and airlines.
  - Limitation: Fixed, rigid structure; hard to adapt to changing requirements.
- **Network Databases (e.g., CODASYL, 1969):**
  - Allowed more complex relationships than hierarchical databases.
  - Predecessor to relational databases.

---

#### **1970s: Rise of Relational Databases**

- **Relational Model Proposed by E.F. Codd (1970):**
  - Introduced the concept of organizing data in tables (rows and columns) with relations.
  - Revolutionary for its simplicity and flexibility.
- **Relational Databases Commercialized (Late 1970s):**
  - Early systems: Oracle (1979), IBM DB2, and Ingres.
  - SQL (Structured Query Language) became the standard for querying relational databases.

---

#### **1980sâ€“1990s: Database Scalability and Expansion**

- **Object-Oriented Databases (1980s):**
  - Combined database principles with object-oriented programming.
  - Used for specialized applications like multimedia.
- **Data Warehousing (1990s):**
  - Emerged to handle analytical processing and large-scale reporting.
  - Example: Teradata pioneered enterprise data warehouses.
- **Distributed Databases (1990s):**
  - Databases spread across multiple locations to improve availability and scalability.

---

#### **2000s: Rise of the Web and NoSQL Databases**

- **Emergence of NoSQL (2000s):**
  - **Why?** Traditional relational databases struggled with web-scale applications, unstructured data, and high velocity.
  - **Types of NoSQL:**
    1. **Document Databases (e.g., MongoDB, CouchDB):**
       - Store data in JSON-like documents, ideal for unstructured or semi-structured data.
    2. **Key-Value Stores (e.g., Redis, DynamoDB):**
       - Simple, fast databases for caching and session management.
    3. **Columnar Databases (e.g., Cassandra, HBase):**
       - Designed for handling big data analytics across distributed systems.
    4. **Graph Databases (e.g., Neo4j, ArangoDB):**
       - Store relationships as first-class citizens, perfect for social networks and recommendation engines.

---

#### **2010s: Big Data and Specialized Databases**

- **Big Data Databases:**
  - Systems like Apache Hadoop (2006) and Apache Spark (2009) supported massive-scale data processing.
  - Relational databases were complemented by NoSQL for high-volume, high-velocity data.
- **Graph Databases Gain Popularity:**
  - Use cases like fraud detection, knowledge graphs, and supply chain management.
  - Neo4j and Amazon Neptune became key players.
- **Time-Series Databases (e.g., InfluxDB, TimescaleDB):**
  - Designed for metrics, logs, and event tracking (IoT, monitoring systems).
- **Cloud Databases:**
  - Shift to managed services like Amazon RDS, Google BigQuery, and Snowflake for ease of use and scalability.

---

#### **2020s: AI, Vector Databases, and Real-Time Needs**

- **Vector Databases (e.g., Pinecone, Weaviate):**
  - Developed for managing high-dimensional vector embeddings used in AI/ML applications (e.g., recommendation systems, semantic search).
  - Purpose-built for the rise of AI models like OpenAI GPT and embedding-based search.
- **Multi-Model Databases:**
  - Databases like ArangoDB and Cosmos DB that support multiple data models (document, graph, key-value) in one system.
- **Graph + AI:**
  - Increased focus on integrating graph databases with AI for knowledge graphs and reasoning.
- **Real-Time Analytics (e.g., Rockset, Apache Druid):**
  - Emerging databases optimized for real-time streaming data and analytics.
- **Serverless Databases:**
  - Systems like AWS Aurora Serverless provide scalability and cost-efficiency by scaling compute automatically.

---

#### **2024 and Beyond: Emerging Trends**

- **Quantum Databases:**
  - Still experimental, aiming to leverage quantum computing for ultra-complex queries.
- **Federated Databases:**
  - Seamlessly querying across multiple, distributed databases without centralization.
- **Embedded AI in Databases:**
  - Databases with built-in AI capabilities for querying and analysis (e.g., vector similarity search).
- **Sustainable Databases:**
  - Focus on energy-efficient designs as sustainability becomes a priority.

## Key Database Categories Today

### Document Stores

- **Purpose**: Flexible schema, JSON-like documents
- **Examples**: MongoDB, CouchDB
- **Best for**: Web applications, content management

### Graph Databases

- **Purpose**: Relationship-focused data
- **Examples**: Neo4j, ArangoDB
- **Best for**: Social networks, recommendation engines

### Key-Value Stores

- **Purpose**: Simple, fast lookups
- **Examples**: Redis, DynamoDB
- **Best for**: Caching, session management

### Vector Databases

- **Purpose**: Similarity search, AI embeddings
- **Examples**: Pinecone, Weaviate
- **Best for**: AI applications, semantic search

### Column-Family Stores

- **Purpose**: Wide-column data, high scalability
- **Examples**: Cassandra, HBase
- **Best for**: Time-series, big data applications

### Time-Series Databases

- **Purpose**: Time-ordered data
- **Examples**: InfluxDB, TimescaleDB
- **Best for**: IoT, monitoring systems

## Current Trends (2024)

1. **AI Integration**: Databases optimized for machine learning workloads
2. **Serverless**: Database-as-a-Service becoming standard
3. **Edge Computing**: Databases designed for distributed edge deployments
4. **Hybrid Solutions**: Combining different database types for specific use cases
5. **Vector Search**: Traditional databases adding vector capabilities

## landscape

- so why so many databases ?
- and what are they all used for ?
- can we use PostgreSQL for no-SQL ?
- what is sharding ?
- where did I put my phone ?

so many questions !

general purpose to specific applications

evolution as use cases required new performance and use cases

## Relation vs non relational database

### **Relational Databases (SQL Databases):**

- **Structure:** Data is stored in **tables** (rows and columns), and relationships between tables are explicitly defined.
- **Schema:** They use a predefined schema, meaning the structure of the data (columns, data types, etc.) is fixed.
- **Query Language:** Use SQL (Structured Query Language) to interact with the data.
- **Strengths:** Great for complex queries, transactions, and ensuring data consistency (ACID compliance).
- **Limitations:** Can struggle with unstructured data or horizontal scalability (adding more servers).

For instance

- **Platforms/Tools:** PostgreSQL, MySQL, Microsoft SQL Server, Oracle DB.
- **Use Cases:** Banking systems, inventory management, CRM systems.

In short: A relational database is like a well-organized spreadsheet where every column is defined, and tables can connect with each other.

### **Non-Relational Databases (NoSQL Databases):**

- **Structure:** Data is stored in flexible formats, such as **JSON documents, key-value pairs, graphs, or columns**.
- **Schema:** Schema-less or dynamic schema, meaning the data structure can change without predefined rules.
- **Query Language:** Doesn't rely on SQL; instead, uses APIs or custom query languages specific to the database type.
  - for Neo4j : ...
  - for MongoDB: ...
- **Strengths:** Ideal for unstructured or semi-structured data, high scalability, and handling massive, distributed workloads.
- **Limitations:** Less suited for complex queries or ensuring strong consistency in some cases.

For instance:

- **Platforms/Tools:**
  - **Document Databases:** MongoDB, CouchDB (good for JSON-like data).
  - **Key-Value Stores:** Redis, DynamoDB (great for caching, session storage).
  - **Graph Databases:** Neo4j, Amazon Neptune (best for relationship-heavy data like social networks).
  - **Columnar Databases:** Cassandra, HBase (optimized for big data analytics).
- **Use Cases:** Social networks, IoT data, real-time analytics, recommendation engines.

A non-relational database is like a flexible folder system where you can store items in different shapes and forms without strict rules.

---

### **Key Use Cases for Each**

| **Database Type**      | **Best For**                                                                                         | **Examples**                              |
|-------------------------|-----------------------------------------------------------------------------------------------------|------------------------------------------|
| **Relational (SQL)**    | - Financial systems requiring strict consistency and transactions.<br>- Inventory management.<br>- ERP/CRM systems. | MySQL, PostgreSQL, Oracle DB             |
| **Non-Relational (NoSQL)** | - Social media platforms.<br>- Real-time analytics.<br>- IoT devices generating unstructured data. | MongoDB, Neo4j, Redis, Cassandra         |

## Schema-less or dynamic schema

Why do we need a special type of database when the data structure is dynamic

Example of a start up like Yuka

lots of information about food products

in a constant evolving context

data evolves fast

- new data becomes available as actors implement data collection. think tracability, safety, etc
- new regulations impose more data
- news, social trends and focus changes rapidly (gluten free, tuna and mercury, )

So you start your database with simple things like

- name, definition, image, description
- nutritional values
- etc

Then nutriscore changes. so you need new nutriscore
but keep the old one.

but not all proudcts implement new nutriscore

let's say you have a nutriscore table

product_id
nutriscore_label
date

so you nutriscore table needs a  new tag, a new column
product_id
nutriscore_label
nutriscore_new_label
date

ok but a lot of products don't have a new nutriscore
so there's plenty of null values in that nutriscore_new_label column
and null values are evil

Side Question: what's wrong with the table above ? how can you avoid having null values at all ?

Question is : is MongoDB only about avoiding null values ?

So is the main justification for mongodb vs sql when the data has varying attirbutes ?

Which would mean a lot of either unknown columns popping up qnd requirring database changes or lots of null values in existing columns ?

- Schema Flexibility ("Unknown Columns"):

In SQL: If you have a Products table and suddenly need to add "allergens" for food items but not for electronics, you'd either:

- Add a column that's NULL for many products
- Create separate tables (ProductFood, ProductElectronics) leading to complexity

In MongoDB: You can just add allergens to food products:

```json
// Food product
{
  "id": 1,
  "name": "Peanut Butter",
  "price": 4.99,
  "allergens": ["peanuts"]
}

// Electronic product
{
  "id": 2,
  "name": "Headphones",
  "price": 59.99,
  "warranty_months": 12
}
```

Nested/Complex Data:

- SQL requires normalization into multiple tables for complex structures
- MongoDB can nest related data naturally

```json
{
  "order_id": 123,
  "customer": {
    "name": "John",
    "address": {
      "street": "123 Main St",
      "city": "Boston"
    }
  },
  "items": [
    {
      "product": "Phone",
      "quantity": 1,
      "custom_engraving": "John's iPhone"
    },
    {
      "product": "Case",
      "quantity": 2
    }
  ]
}
```

Rapid Iteration:

- When your application is evolving quickly and data requirements change often
- Startups or new products where the data model isn't fully understood yet
- A/B testing different features that might require different data structures

In short MongoDB is about avoiding normalization

> The advantage of No_SQL database over SQL databases (MongoDB over PostgreSQL) is that no-sql database do not expect or require normalization

The key advantage of MongoDB over SQL databases is that it doesn't require strict normalization, which makes it particularly suitable when:

- Your data naturally fits a document structure rather than tables
- Different records need different fields (polymorphism)
- You want to store related data together rather than spread across tables
- Your schema needs to evolve quickly
- You prioritize development speed over strict data consistency"

## What about Graph database ?

SQL database are called relational databases, the relation between object (tables) is explicitly defined by foreign keys.

Product ->  Vegetables -> Location Origin
Product ->  Vegetables -> Bio / not Bio
Product -> nutrition (sugar, fat etc)
Product -> nutriscore labels
Product -> ConsumeBy

![product veggies schema relation](/img/product-veggies-schema-relation.png)

What's interesting in that schema is that the LLM naturally added some meaning, some information to the relations between tables.

But in fact the same database schema in a SQL database would lack any information on the nature of the relation between the tables.

We would only have an indication of the cardinality of the relation:

- 1 to 1
- 1 to many

Graph database however are all about **relationships**.

The key differentiating concept of graph databases vs SQL databases is:

In graph databases (Neo4j), **relationships** are as important as the data itself and are stored explicitly.

These relationships:

- Have their own properties
- Are stored as connections
- Can be traversed efficiently in any direction

While in SQL:

- Relationships are implicit through foreign keys
- Must be reconstructed through JOINs
- Get exponentially more complex/slower as you follow multiple levels of connections

Simple analogy [TODO not great]:

- SQL is like having a list of people and a separate list of who knows who
  - you need to keep checking both lists to find "friends of friends"
- Neo4j is like having everyone in a room with actual strings connecting friends
  - you just follow the strings to find "friends of friends"

That's why Neo4j excels at questions like:

- "Find all friends of friends who like jazz and live in Paris"
- "What's the shortest path between person A and person B?"
- "Who are the most influential people in this network?"

## conclusion

So SQL aka relational databases are great for data sr=ucture that does not change often and where realtions between obects are stable.

No-SQL database like MongoDB : great when data specifications are evolving rapidly or are not set in stone, flexible schema

Graph database : relation is key. it's not only thta there is a relation but also what is that relation about.
